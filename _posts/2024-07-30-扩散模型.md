---
layout: post
comments: True
title: "扩散模型"
date: 2024-07-30 01:09:00

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

Diffusion models可以说是现如今机器学习领域最火的模型，其不仅在生成模型领域性能上大大超越了之前的那些前辈们，包括GAN，VAE，flow-based模型等，还在多模态领域也引起了革命，比如StableDiffusion等。而且由于diffusion模型，尤其是结合文本和图像的多模态diffusion模型，其所学习到的feature具有很好的semantics可解释性，所以pre-trained好的diffusion模型现在也被用于很多任务之中，最火的比如说基于diffusion模型loss改进的score distillation sampling (SDS)的各种diffusion-based 3D representation learning（比如DreamFusion，Magic3D，zero-1-to-3等）都具有惊艳的效果。而本文，则从原理到应用到代码，综合的介绍一下diffusion models，这个如今AI领域的核心模型。

在开始正式的介绍之前，首先来看看diffusion model和之前的那些生成模型的对比。

![1]({{ '/assets/images/diffusion_1.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[Lil'Log: What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)*

GAN的缺点在于比较难以训练（discriminator过好的话，generator更新的梯度会很小，训练不动，而discriminator过差的话，generator的更新梯度方向就是错误的，训练结果不对。即使是后续改进的Wasserstein GAN也没有完全解决这个问题）。而VAE的缺点在于需要假设分布是简单的（比如高斯分布），否则难以求解。而flow-based模型则需要transformation functions是invertible的，也限制了模型的flexibility。

而diffusion模型不同于之前的生成模型范式，提出了个新的框架，其受到了物理学里的non-equilibrium thermodynamics的启发，简单举个例子，在水中滴入墨水，那么墨水就会逐渐扩散到整杯水都会变黑。diffusion模型的思路就是，在”干净“的原输入数据（比如说图片）上逐渐加上噪声，一般来说就是0均值的高斯噪声，每一步都是在前一次的基础上再往上添加。如果能够控制好这些高斯噪声的方差大小的话，理论上足够长的时间，我们就可以得到一个均值为0，方差为1的标准高斯分布了（这样说不太准确，因为最终得到的是一个被污染了的数据，准确来说是，最终我们得到的这个被污染的数据，其分布服从均值为0，方差为1的高斯分布）。但我们想要的并不是高斯噪声，我们想要的是能生成和输入数据”长得像“的新的干净的数据。而diffusion模型的做法是，从一个均值为0，方差为1的高斯分布出发，采样一个值，然后逐步让一个Denoiser来将这个值里的噪声逐步去除掉，也就是将之前的加噪声的过程逆过来，如果这个逆过程能够很好的模拟之前的添加噪声的逆过程，那么很多步之后，我们就应该能够得到去除掉噪声的干净的数据了。因为这个去噪过程的输入是随即从标准高斯分布采样的值，所以具有随机性，从而这样得到的干净的数据也是具有随机性的，也就是说每次采样都可以有不同的生成数据输出了。上述这两个过程，就分别叫做diffusion model的前向过程，和反向过程，也叫做加噪过程和去噪过程。

![2]({{ '/assets/images/diffusion_2.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[Lil'Log: What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)*

一般情况下，上述过程里的denoiser，由一个神经网络来实现。对于每个”干净“的输入图片$$x_0$$，先采样一个时间$$t$$，然后给$$x_0$$添加噪声，这个噪声的大小和$$t$$有关，然后将加噪后的数据，以及$$t$$，同时输入给denoiser，其输出和$$x_0$$之间的差别，就是整个训练的loss。

介绍diffusion模型的博客和论文很多，而最重要的是提出diffusion模型的两篇论文：[DDPM](https://arxiv.org/pdf/2006.11239)和[NCSN](https://arxiv.org/pdf/1907.05600)，这两篇论文分别从不同的角度介绍了diffusion模型，也是接下来理论介绍diffusion模型的两个角度。

## 1. 基本原理 （DDPM）

如之前所说，diffusion模型可以从两个角度来理解其原理，其中DDPM（diffusion  probabilistic models）的解释更容易理解，从而先从此角度来说。

### (1). 前向扩散过程（forward diffusion process）

从一个给定的数据分布$$q(x)$$里采样一个数据$$x_0$$，$$x_0 \sim q(x)$$（$$x_0$$就可以被理解为我们手里已有的数据，而$$q(x)$$是已有的数据潜在的数据分布，是未知的），扩散模型的一个前向扩散过程，就是不断地给数据添加高斯噪声的过程，假设一共添加了$$T$$步，那么就会得到一系列noisy的数据：$$x_1, x_2, \cdots, x_T$$，而每一步具体添加多少噪声，则是由一组超参数$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$决定的:

$$q(x_t \vert x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I}), \  \text{where} \  t=1,2,\cdots,T$$

可以看出来，$$x_0, x_1, \cdots, x_T$$是个马尔可夫链，从而$$x_1, \cdots, x_T$$在$$x_0$$条件下的联合分布就可以写成如下形式：

$$q(x_{1:T} \vert x_0) = \Pi_{t=1}^T q(x_t \vert x_{t-1})$$

原本“干净”的数据$$x_0$$，随着时间的推进，增加的噪声越来越多，逐渐就失去了原本的structure，在合适的$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$的设置下，以及$$T \rightarrow \infty$$的情况下，$$x_T \sim \mathcal{N}(0, \mathbf{I})$$。

而实际上，前向过程的一个良好的性质是，我们可以得到$$x_t$$与$$x_0$$的closed form的关系（$$1 \leq t \leq T$$）：

记$$\alpha_t = 1 - \beta_t$$，$$\bar{\alpha}_t = \Pi_{i=1}^t \alpha_i$$，那么：

$$
\begin{align}

x_t &= \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-1} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + (\sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1}) \\
&= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_{t}\alpha_{t-1}}\bar{\epsilon}_2, \  \text{where} \  \bar{\epsilon}_2 \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \cdots \\
&= \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_t, \  \text{where} \  \bar{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
\end{align}
$$

上述推导用到了一个结论：$$x \sim \mathcal{N}(\mathbf{0}, \sigma_1^2 \mathbf{I}), y \sim \mathcal{N}(\mathbf{0}, \sigma_2^2 \mathbf{I})$$，那么$$x+y \sim \mathcal{N}(\mathbf{0}, (\sigma_1^2 + \sigma_2^2) \mathbf{I})$$。

上述过程的第一行里，$$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$用到了一个重参数化技巧（reparametrization trick），将$$x_t$$的随机性，转移到了$$\epsilon_{t-1}$$上，而$$\epsilon_{t-1}$$是从一个无可学习参数的标准高斯分布采样来的。这样做的好处是，因为在计算loss反向传播的时候，需要计算loss对于$$x_t$$的导数，如果$$x_t$$是采样来的，采样过程是离散的而且不可导，这样就没法算了。

由上述推导，可以得到在$$x_0$$条件下$$x_t$$的分布是个高斯分布：

$$q(x_t \vert x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1 - \bar{\alpha}_t)\mathbf{I})$$

一般来说，对于超参数$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$的设置是，随着$$t$$的增大，噪声的程度可以越来越大，也就是说$$\beta_1 < \beta_2 < \cdots < \beta_T$$，从而$$\alpha_1 > \alpha_2 > \cdots > \alpha_T$$，且$$\bar{\alpha}_1 > \bar{\alpha}_2 > \cdots > \bar{\alpha}_T$$。

### (2). 反向扩散过程（reverse diffusion process）

如果我们可以建模上述前向扩散过程的逆过程，也就是建模$$q(x_{t-1} \vert x_t)$$的话，那么基于一个从标准高斯分布采样得到的纯噪声数据$$x_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$，就可以一步步回退，逐步去除噪声，最终得到一个新的”干净“的$$x_0$$，而因为$$x_T$$的采样是具有随机性的，所以每次得到的$$x_0$$也不一样，这样就可以源源不断地生成”干净“的数据了。

我们有如下结论：如果$$\beta_t$$足够小的话，那么如果$$q(x_t \vert x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I})$$是个高斯分布，那么$$q(x_{t-1} \vert x_t)$$也是个高斯分布。但这个高斯分布的均值和方差无法解析表达。从而我们考虑用一个带有可学习参数$$\theta$$的模型$$p_{\theta}$$来对$$q(x_{t-1} \vert x_t)$$进行建模：

$$p_{\theta}(x_{t-1} \vert x_t) = \mathcal{x_{t-1}; \mu_{\theta}(x_t, t), \Sigma_{\theta}(x_t, t)}$$

我们同样假设反向扩散过程也是个马尔可夫链，也就是说：

$$q(x_{0:T}) = q(x_T) \Pi_{t=1}^T q(x_{t-1} \vert x_t) = q(x_T) \Pi_{t=1}^T p_{\theta}(x_{t-1} \vert x_t)$$

如果我们在分布$$q(x_{t-1} \vert x_t)$$上再加上条件$$x_0$$的话，也就是考虑分布$$q(x_{t-1} \vert x_t, x_0)$$，有如下结果：

$$
\begin{align}

q(x_{t-1} \vert x_t, x_0) &= q(x_t \vert x_{t-1}, x_0) \frac{q(x_{t-1} \vert x_0)}{q(x_t \vert x_0)} = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I}) \frac{\mathcal{N}(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}}x_0, (1-\bar{\alpha}_{t-1})\mathbf{I})}{\mathcal{N}(x_{t}; \sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)\mathbf{I})}\\
& \propto exp(-\frac{1}{2} \frac{(x_t - \sqrt{\alpha_t} x_{t-1})^T(x_t - \sqrt{\alpha_t} x_{t-1})}{\beta_t} + \frac{1}{2} \frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})^T(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})}{1 - \bar{\alpha}_{t-1}}) - \frac{1}{2} \frac{(x_{t} - \sqrt{\bar{\alpha}_t} x_{0})^T(x_{t} - \sqrt{\bar{\alpha}_t} x_{0})}{1 - \bar{\alpha}_t})\\
&= exp(-\frac{1}{2}((\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha_{t-1}}})x_{t-1}^Tx_{t-1} - (\frac{2 \sqrt{\alpha_t}}{\beta_t}x_t^T + \frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}x_0^T)x_{t-1})+ C(x_0, x_t)), \  \text{where} \  C(x_0, x_t) \  \text{is} \  \text{a} \  \text{constant} \  \text{w.r.t.} \  x_{t-1}
\end{align}
$$

从这个形式可以看出，$$q(x_{t-1} \vert x_t, x_0)$$也满足高斯分布，$$q(x_{t-1} \vert x_t, x_0) = \mathcal{N}(x_{t-1} \vert \tilde{\mu}(x_t, x_0), \tilde{\beta_t} \mathbf{I})$$，其中

$$\tilde{\beta_t} = 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha}_{t-1}}) = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t, \tilde{\mu}(x_t, x_0) = (\frac{2 \sqrt{\alpha_t}}{\beta_t}x_t + \frac{2 \sqrt{\bar{\alpha_{t-1}}}}{1-\bar{\alpha_{t-1}}}x_0) / (\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha}_{t-1}}) = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0$$

而之前我们有结论：$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_t, \  \text{where} \  \bar{\epsilon}_t \sim \mathcal{N}(\textbf{0}, \textbf{I})$$，也就是，$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bar{\epsilon}_t)$$，带入$$\tilde{\mu}(x_t, x_0)$$上面的结果，可得：$$\tilde{\mu}(x_t, x_0) = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$，与$$x_0$$无关了，因此也可以记为$$\tilde{\mu}_t$$。

上述的推导过程表明，$$q(x_{t-1} \vert x_t, x_0)$$可以有closed-form的结果。先把这个结果放在一旁。

### (3). 损失函数

既然我们希望用一个带参数的分布$$p_{\theta}$$来对$$q(x_{t-1} \vert x_t)$$进行近似，那么我们就需要定义损失函数来让$$p_{\theta}$$与$$q(x_{t-1} \vert x_t)$$尽可能靠近，如下的推导对$$p_{\theta}$$的形式不做任何假设。

我们可以发现，实际上$$p_{\theta}(x_{t-1} \vert x_t)$$很像VAE里的$$q_{\phi}(z \vert x)$$，而$$q(x_{t-1} \vert x_t)$$则是VAE的decoder的未知后验分布$$p_{\theta}(z \vert x)$$（这里的$$\theta$$和之前的$$\theta$$不一样，这里指的是VAE里的分布）。从而根据这个观察，我们也可以仿照VAE的损失函数，定义如下的损失函数：

$$
\begin{align}
-log p_{\theta}(x_0) &\leq -log p_{\theta}(x_0) + \textbf{D}_{\textbf{KL}} (q(x_{1:T} \vert x_0) \Vert p_{\theta}(x_{1:T} \vert x_0)) = -log p_{\theta}(x_0) + \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{1:T} \vert x_0)} \right] \\
&= -log p_{\theta}(x_0) + \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} + log p_{\theta}(x_0) \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} \right]
\end{align}
$$

对上个式子两侧以$$q(x_0)$$为分布取期望，则有：

$$ - \mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log p_{\theta}(x_0) \right] \leq \mathop{\mathbb{E}}\limits_{q(x_{0:T})} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} \right]$$

记上面式子的右侧为$$\mathcal{L}_{VLB}$$。

我们再来考虑$$q(x_0)$$和$$p_{\theta}(x_0)$$之间的cross entropy：

$$
\begin{align}
\mathcal{L}_{CE} &= -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log p_{\theta}(x_0) \right] = -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log \int p_{\theta}(x_{0:T}) dx_{1:T} \right] = -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log \int q(x_{1:T} \vert x_0) \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)} dx_{1:T} \right] \\
&= -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log -\mathop{\mathbb{E}}\limits_{q(x_{1:T} \vert x_0)} (\frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)}) \right] \leq -\mathop{\mathbb{E}}\limits_{q(x_0)} \mathop{\mathbb{E}}\limits_{q(x_{1:T} \vert x_0)} log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)} = - \mathop{\mathbb{E}}\limits_{q(x_{0:T} \vert x_0)} log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)} = \mathcal{L}_{VLB}
\end{align}
$$

回到之前的结果：$$-log p_{\theta}(x_0) \leq \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} \right]$$，记右侧这个式子为$$\mathcal{L}_{VLB}^{\ast}$$，也就是说，$$\mathcal{L}_{VLB} = \mathop{\mathbb{E}}\limits_{q(x_0)} \left[ \mathcal{L}_{VLB}^{\ast} \right]$$，那么：

$$
\begin{align}
\mathcal{L}_{VLB}^{\ast} &= \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{\Pi_{t=1}^T q(x_t \vert x_{t-1})}{p_{\theta}(x_T) \Pi_{t=1}^T p_{\theta}(x_{t-1} \vert x_t)} \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_t \vert x_{t-1})}{p_{\theta}(x_{t-1} \vert x_t)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] \\
&= \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_t \vert x_{t-1}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}\frac{q(x_t \vert x_0)}{q(x_{t-1} \vert x_0)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] \\
&= \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) + \sum_{t=2}^T log (\frac{q(x_t \vert x_0)}{q(x_{t-1} \vert x_0)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_T \vert x_0)}{p_{\theta}(x_T)} - log p_{\theta}(x_0 \vert x_1) + \sum_{t=2}^T log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) \right] \\
&= -\mathop{\mathbb{E}}\limits_{x_1 \sim q(x_1 \vert x_0)} \left[ log p_{\theta}(x_0 \vert x_1) \right] + \mathop{\mathbb{E}}\limits_{x_T \sim q(x_T \vert x_0)} \left[ log \frac{q(x_T \vert x_0)}{p_{\theta}(x_T)} \right] + \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_{t-1}, x_t \sim q(x_{t-1}, x_t \vert x_0)} \left[ log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) \right]\\
&= -\mathop{\mathbb{E}}\limits_{x_1 \sim q(x_1 \vert x_0)} \left[ log p_{\theta}(x_0 \vert x_1) \right] + \textbf{D}_{\textbf{KL}}(q(x_T \vert x_0) \Vert p(x_T)) + \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_{t-1}, x_t \sim q(x_t \vert x_0)q(x_{t-1} \vert x_t, x_0)} \left[ log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) \right] \\
&= -\mathop{\mathbb{E}}\limits_{x_1 \sim q(x_1 \vert x_0)} \left[ log p_{\theta}(x_0 \vert x_1) \right] + \textbf{D}_{\textbf{KL}}(q(x_T \vert x_0) \Vert p(x_T)) + \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_t \sim q(x_t \vert x_0)} \left[ \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) \right]
\end{align}
$$

其中，上面式子右侧第一项叫做reconstruction term，第二项叫做prior matching term，第三项叫做denoising matching term。

denoising matching term里的每一项，由之前的结果可知：

$$q(x_{t-1} \vert x_t, x_0) = \mathcal{N}(x_{t-1}; \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t), \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t)$$

为了让$$p_{\theta}(x_{t-1} \vert x_t)$$和$$q(x_{t-1} \vert x_t, x_0)$$之间的$$DL$$散度尽可能小，我们则也假设$$p_{\theta}(x_{t-1} \vert x_t)$$为高斯分布（与之前的假设不谋而合）。因为我们已经计算出来$$q(x_{t-1} \vert x_t, x_0)$$的方差为$$\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t$$是个常数，所以$$p_{\theta}(x_{t-1} \vert x_t)$$的方差也是该值，但是$$q(x_{t-1} \vert x_t, x_0)$$的均值是$$\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$，其中$$\bar{\epsilon}_t$$是每次前向扩散过程从标准高斯分布中随机采样的值，这是未知的（因为有$$x_t, x_0, \bar{\epsilon_{t}}$$之间的关系，$$x_t$$在反向扩散过程中是已知的，$$x_0$$是我们希望要得到的，$$x_0$$的未知性和$$\bar{\epsilon}_t$$的未知性等价），所以没办法直接让$$p_{\theta}(x_{t-1} \vert x_t)$$的均值就等于它，从而这就成为了扩散模型需要利用神经网络进行学习的部分，记$$p_{\theta}(x_{t-1} \vert x_t)$$的均值为$$\mu_{\theta}$$。

因为$$p_{\theta}(x_{t-1} \vert x_t)$$和$$q(x_{t-1} \vert x_t, x_0)$$都是高斯分布，实际上它们之间的$$DL$$散度是可以closed-form计算出来的：

$$\textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_t, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) = \frac{1}{2\tilde{\beta_t}} \Vert \mu_{\theta} - \tilde{\mu}_t \Vert_2^2$$

对于reconstruction term，在原论文中用另一个单独的网络来优化，即认为$$p_{\theta^{'}}(x_0 \vert x_1) \sim \mathcal{N}(x_0; \tilde{\mu}_{\theta^{'}}(x_1, t=1), \Sigma_{\theta^{'}}(x_1, t=1))$$。而prior matching term不含可学习参数$$\theta$$。

所以说，最小化$$\mathcal{L}_{VLB}^{\ast}$$（也就是等价于最小化$$\mathcal{L}_{VLB}$$）的重点就在于最小化denoising matching term里的每一项$$p_{\theta}(x_{t-1} \vert x_t)$$和$$q(x_{t-1} \vert x_t, x_0)$$之间的$$DL$$散度，$$2 \leq t \leq T$$。而根据上面的推导过程可知，也就等价于最小化每个高斯分布$$p_{\theta}(x_{t-1} \vert x_t)$$的均值和高斯分布$$q(x_{t-1} \vert x_t, x_0)$$的均值。$$p_{\theta}(x_{t-1} \vert x_t)$$的均值由网络预测出，网络的输入是$$x_t$$和时间$$t$$，而$$q(x_{t-1} \vert x_t, x_0)$$的均值是已知的，有两种写法：

$$\tilde{\mu}(x_t, x_0) = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0$$

$$\tilde{\mu}(x_t, x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$

从而我们的神经网络输出也可以有两种：（1）输入$$x_t, t$$，预测$$x_0$$；（2）输入$$x_t, t$$，预测$$\bar{\epsilon}_t$$。记$$f_{\theta}(x_t, t)$$为网络的输出。

对于第一种情况：

$$\mu_{\theta} = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}f_{\theta}(x_t, t)$$

从而：

$$\arg\min\limits_{\theta} \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) = \arg\min\limits_{\theta} \frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2} \Vert f_{\theta}(x_t, t) - x_0 \Vert_2^2$$

对于第二种情况：

$$\mu_{\theta} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} f_{\theta}(x_t, t))$$

从而：

$$\arg\min\limits_{\theta} \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) = \arg\min\limits_{\theta} \frac{1}{2\tilde{\beta_t} \alpha_t} \frac{(1-\alpha_t)^2}{1-\bar{\alpha}_t} \Vert f_{\theta}(x_t, t) - \bar{\alpha}_t \Vert_2^2$$

diffusion模型一般采用第二种方式，因为对噪声进行建模会更加关注细节（噪声相对于原数据$$x_0$$要更小一些）。

在第二种方式下，回到$$\mathcal{L}_{VLB}$$中，则是：

$$
\begin{align}
\arg\min\limits_{\theta} \mathcal{L}_{VLB} &= \arg\min\limits_{\theta} \sum_{t=2}^T  \mathop{\mathbb{E}}\limits_{x_t, x_0 \sim q(x_t, x_0)} \left[ \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) \right] = \arg\min\limits_{\theta} \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_t, x_0 \sim q(x_t, x_0)} \left[ \frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2} \Vert f_{\theta}(x_t, t) - \bar{\epsilon}_t \Vert_2^2 \right] \\
&= \arg\min\limits_{\theta} \mathop{\mathbb{E}}\limits_{x_0 \sim q(x_0), \bar{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), t \sim \left[2, T \right]} \left[\frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2} \Vert f_{\theta}(x_t, t) - \bar{\epsilon}_t \Vert_2^2 \right]
\end{align}
$$

所以说反向扩散过程（denoising）过程的本质，在于让模型学会以任意时刻$$t$$时加噪的数据以及时间$$t$$作为输入，都可以学到这个时刻的数据在“干净”数据上所加上的噪声（也就等价于学到“干净”的数据）。

DDPM模型的训练过程如下左图。而在训练完成之后，想要生成数据（采样）的过程如下右图

![3]({{ '/assets/images/diffusion_3.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[Lil'Log: What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)*


### (4). 一些补充说明

**关于超参数$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$的选择**

根据假设，$$q(x_t \vert x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I}), \  \text{where} \  t=1,2,\cdots,T$$。也就是说，$$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$，但是为什么均值和方差的系数有这样的关系，并没有说明。下面给出一些intuition。

首先，假设$$x_t$$与$$x_{t-1}$$的关系是线性的（因为最简单），即：$$x_t = a_t x_{t-1} + b_t \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$。因为前向扩散过程是个加噪的过程，所以$$x_t$$应该是相对于$$x_{t-1}$$是衰减的，从而$$a_t, b_t \in (0,1)$$。

那么，我们将$$x_t$$的表达式不断地往后迭代，使用$$x_0$$来表示$$x_t$$：

$$x_t = a_t x_{t-1} + b_t \epsilon_{t-1} = a_t a_{t-1} x_{t-2} + a_t b_{t-1} \epsilon_{t-2} + b_t \epsilon_{t-1} = \cdots = (a_t a_{t-1} \cdots a_1) x_0 + (a_t \cdots a_2)b_1 \epsilon_{0} + \cdots + a_t b_{t-1} \epsilon_{t-2} + b_t \epsilon_{t-1}$$

从而，将第二项到最后一项全部综合起来，其也满足一个高斯分布，方差为$$\lbrace (a_t \cdots a_2b_1)^2 + \cdots + (a_t b_{t-1})^2 + (b_t)^2) \mathbf{I}$$。如果再考虑将第一项$$x_0$$的系数的平方和考虑进来，那么此时$$x_0$$系数的平方，与后面的方差的系数的平方和就是：$$(a_t \cdots a_1)^2 + (a_t \cdots a_2b_1)^2 + \cdots + (a_t b_{t-1})^2 + (b_t)^2) = a_t^2(a_{t-1}^2(\cdots(a_2^2(a_1^2+b_1^2)+b_2^2)+\cdots)+b_{t-1}^2)+b_t^2$$。如果令$$a_i^2 + b_i^2 =1$$对于所有的$$1\leq i \leq t$$成立，则该平方和就是1，而此时这些超参数的选择，就是前文所述的。

**图解DDPM过程**

训练过程：

![-1]({{ '/assets/images/diffusion_-1.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

![0]({{ '/assets/images/diffusion_0.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

采样过程：

![-2]({{ '/assets/images/diffusion_-2.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

**DDPM为什么要采样那么多步？**

DDPM存在一个非常明显的缺点，就是采样速度过慢，在生成一张图片的过程中，我们需要进行$$T$$次迭代，而一般T都是非常大的（e.g.~1000）。因此DDPM虽然图像的质量和多样性很好，但生成效率非常低。为了解决这个问题，[DENOISING DIFFUSION IMPLICIT MODELS](https://arxiv.org/pdf/2010.02502)提出了一个新的模型（或者称为采样方式）叫做Denoising Diffusion Implicit Models（DDIM）。

（1）为什么DDPM一定要这么多次采样？

加快DDPM的生成效率。最容易想到的两种方法：
* 减小$$T$$
* “跳步”（i.e. 不再严格按照$$x_{t-1}到$$x_t$$的顺序来采样）

下面依次讨论。

**第一，减小$$T$$是否可行？答案是否定的**

因为在DDPM中，有如下关系：

$$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon$$

对于每个$$t$$，$$1-\alpha_t$$都需要接近于0，$$\alpha_t$$都需要接近1，这是因为：
 * 只有$$1-\alpha_t$$比较小的时候，才能满足$$q(x_{t-1} \vert x_t)$$也满足近似为高斯分布的假设
 * $$x_{t-1}$$的系数$$\alpha_t$$要尽量接近于1，这束为了保证$$t$$时刻的加噪数据$$x_t$$要尽量保留$$t-1$$时刻的大体分布，如果噪声破坏过大，就难以让模型学习了

同时，我们也有如下关系：

$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$$

根据DDPM里的假设，我们希望在$$T$$时刻，也就是最后时刻，$$x_T$$是近似于标准正态分布的，也就是说$$\sqrt{\bar{\alpha}_T}$$接近于0，$$\sqrt{1 - \bar{\alpha}_T}$$接近于1。从而在$$\alpha_t, t=1,2,\cdots,T$$都接近于1的条件下，只有$$T$$足够大，才能满足$$\sqrt{\bar{\alpha}_T}$$接近于0。

**第二，为什么一定要从$$x_T$$开始一步步的降噪，即从$$x_t$$到$$x_{t-1}$$，$$t=T, T-1, \cdots, 1$$，能否跳步？答案也是否定的**

首先，能否由$$x_t$$直接得到$$x_s$$（其中$$s<k$$），答案是否定的，因为无法直接得到$$q(x_s \vert x_k)$$的表达式。

根据之前的损失函数的推导，DDPM的优化目标是让$$q(x_{t-1} \vert x_t)$$去近似分布$$q(x_{t-1} \vert x_t, x_0)$$，而后者在前述推导中是通过贝叶斯公式得到closed-form的结果的：

$$q(x_{t-1} \vert x_t, x_0) = \frac{q(x_t \vert x_{t-1})q(x_{t-1} \vert x_0)}{q(x_t \vert x_0)}$$

按照前述的结果，$$q(x_{t-1} \vert x_t, x_0)$$是一个高斯分布，所以$$q(x_{t-1} \vert x_t)$$也需要是一个高斯分布，且均值需要近似于$$q(x_{t-1} \vert x_t, x_0)$$的均值$$\tilde{\mu}(x_t, x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$（方差是个常数，可以直接设置为相等）。

而在DDPM中，是利用网络来近似这个均值的（近似$$x_0$$或者近似$$\bar{\epsilon}_t$$，注意到$$x_0$$和$$x_t$$之间有$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$$）：

$$\mu_{\theta} = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}f_{\theta}(x_t, t)$$

或者

$$\mu_{\theta} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} f_{\theta}(x_t, t))$$

但不管是哪种方式，其近似的都是分布$$q(x_{t-1} \vert x_t)$$的均值，而如果将分布$$q(x_{t-1} \vert x_t)$$改成别的形式，比如$$q(x_{s} \vert x_t)$$（其中$$s < k$$），我们就没有上面的那些推导的结果了。

其次，那能否直接由$$x_t$$得到$$x_0$$？

答案是可以的，$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1-\bar{\alpha}_t} \bar{\epsilon}_t)$$，而网络正好是预测$$\bar{\epsilon}_t$$的值的，即：$$f_{\theta}(x_t, t) \approx \bar{\epsilon}_t$$，从而可以直接由$$x_t$$得到$$x_0$$：

$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1-\bar{\alpha}_t} f_{\theta}(x_t, t))$$

实际上，上述操作也就等价于在设计网络的时候，让网络对于不同的加噪数据$$x_t$$和timestep $$t$$输入，输出$$x_0$$，而并非输出噪声估计$$\bar{\epsilon}_t$$。

但为何在实际操作中不这么做，原因只有一个，就是实验表明这样操作生成效果差。

上述具体解释在[DDPM的原论文](https://hojonathanho.github.io/diffusion/assets/denoising_diffusion20.pdf)里也有说明（section 3.2）：

> To summarize, we can train the reverse process mean function approximator \textbf{\mu}_{\theta} to predict $$\mu_t$$, or by modifying its parameterization, we can train it to predict $$\epsilon_t$$. (**There is also the possibility of predicting $$x_0$$, but we found this to lead to worse sample quality early in our experiments.**) We have shown that the $$epsilon$$-prediction parameterization both resembles Langevin dynamics and simplifies the diffusion model’s variational bound to an objective that resembles denoising score matching. Nonetheless, it is just another parameterization of $$p_{\theta}(x_{t-1} \vert x_t)$$, so we verify its effectiveness in Section 4 in an ablation where we compare predicting $$\epsilon_t$$ against predicting $$\mu_t$$.


**参考文献**
1. https://lilianweng.github.io/posts/2021-07-11-diffusion-models/
2. https://zhuanlan.zhihu.com/p/565901160
3. https://zhuanlan.zhihu.com/p/708195611 

### (5). 代码

[这里](https://github.com/xiaohu2015/nngen/blob/main/models/diffusion_models/ddpm_mnist.ipynb)提供了不错的基于DDPM的diffusion models的pytorch实现。

[这里](https://github.com/lucidrains/denoising-diffusion-pytorch)也提供了一个代码实现。[这里](https://github.com/nmwsharp/diffusion-net)也提供了一个代码实现。

## 2. 基本原理（NCSN）

noise-conditioned score network，简称NCSN，在2019年有宋飏等人提出，是早于DDPM的，但是由于形式更为复杂，所以并没有火起来，直到后来人们才发现，其蕴含着比DDPM更深刻的原理（实际上DDPM可以看作NCSN的一种特例）。而之后，宋飏又在ICLR2021上发表了[一篇论文](https://arxiv.org/pdf/2011.13456)用来在SDE框架下解释DDPM和NCSN的统一性。

NCSN，或者更广泛一点说，scored-based generative model这一类模型，的优点有：
* 可以有媲美GAN的生成质量，但无需对抗训练，从而避免了类似于GAN那种训练困境
* 灵活的模型框架选择，无需像flow-based models那样，只能选择可以表示invertible transformation的框架

### (1). 从生成模型到score-based model

**1). 生成模型**

从一个未知的数据分布$$p(x)$$中，独立的采样出了一系列的样本$$\lbrace x_1, \cdots x_N \rbrace$$，这些既是数据集。而生成模型的目的就是，从这个含有有限样本的数据集出发，去拟合数据背后的分布$$p(x)$$，从而就可以获得无穷无尽的样本了。

为了实现从数据集估计其分布$$p(x)$$的目标，首先需要去对$$p(x)$$进行建模。而最常见的建模方式就是parametric模型，即首先选择一类概率分布并且认为其覆盖了$$p(x)$$，用带参数的分布$$p_{\theta}(x)$$来表示这一簇分布。而我们的目的，则是从数据集来估计这个参数$$\theta$$，从而得到$$p_{\theta^{\ast}}(x) \approx p(x)$$。

而很多时候，我们都是用energy-based的方法来表示$$p_{\theta}(x)$$，即

$$p_{\theta}(x) = e^{-f_{\theta}(x)} / Z_{\theta}$$

其中$$f_{\theta}(x) \in \mathbb{R}$$是任意的以$$\theta$$为参数的函数，而与$$x$$无关但与$$\theta$$有关的$$Z_{\theta}$$则是归一化常数，用来获得最终的分布$$p_{\theta}(x)$$。

最常见的对数据集的拟合方式就是使用最大似然估计：

$$\theta^{\ast} = \arg\max\limits_{\theta} \sum_{i=1}^N log p_{\theta}(x_i) = \arg\min\limits_{\theta} NlogZ_{\theta} + \sum_{i=1}^N f_{\theta}(x_i)$$

但是由上面的式子可以看到，objective function里含有$$Z_{\theta}$$，而这个值往往是难以估计的。

为了解决这个问题，宋飏等人提出了score-based model，其基本思想是，与其对$$p(x)$$建模，不如对$$p(x)$$对数据$$x$$的梯度进行建模来间接获取数据分布$$p(x)$$，因为$$Z_{\theta}$$与$$x$$无关，所以其关于$$x$$的梯度就是0，从而就可以避免对$$Z_{\theta}$$进行估计。


**2). score-based model**

score function，或者称为score，也就是NCSN那篇论文标题中的gradients of the data distribution，具体来说是概率密度函数对数的梯度：$$\nabla_x log p(x)$$。而用来对score进行建模/拟合的模型，就叫做score-based model，记这类模型为$$s_{\theta}(x)$$，其中$$\theta$$是模型可学习参数。

和直接建模数据分布函数$$p(x)$$不同，score-based model并不会受到归一化系数$$Z_{\theta}$$的影响。如果使用energy-based model来建模$$p(x)$$的化，那么$$s_{\theta}(x) = \nabla_x log p_{\theta}(x) = \nabla_x (-f_{\theta}(x) - log Z_{\theta}) = -\nabla_x f_{\theta}(x)$$。这样的话，我们就可以使用各种灵活的模型，而不需要考虑归一化参数是否容易求解这样一个巨大的制约了。

score的物理意义是：对于每个点$$x$$来说，该点的score就是数据的对数概率密度函数在该点$$x$$增长最快的方向

![4]({{ '/assets/images/diffusion_4.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[DiffusionModel-NCSN原理与推导](https://zhuanlan.zhihu.com/p/670052757)*

上图可视化了一个2维分布概率密度函数对数的梯度（在每个点都有方向和大小，因为梯度是个向量）。如图所示，图里有两个中心，而这即代表了$$log p_{\theta}(x)$$取极大值的地方，即最能代表此数据先验分布的区域。对于生成模型而言，我们期望生成的数据，就应该位于这些数据先验分布值大的区域。所以说如果我们可以估计score，在有了score之后，就可以利用score来确定$$p_{\theta}(x)$$极大值的方位，从而就可以有更理想的生成结果。而在有score的情况下，从任意点出发，到达$$p_{\theta}(x)$$某个极大值的方法，就是朗之万采样（Langevin Sampling）。

**3). Langevin采样**

假设我们已经有了一个训练好的score-based model $$s_{\theta}(x)$$，可以对于任意输入的$$x$$，输出该点的score了，那么该如何采样，才能靠近$$p_{\theta}(x)$$的极大值点呢？

这实际上是一个Langevin dynamics问题（朗之万动力学），其提供了一种仅利用某个分布$$p(x)$$的score function，即$$\nabla_x log p(x)$$（对数概率密度函数的梯度），就可以对分布$$p(x)$$进行采样的MCMC方法。其具体操作如下：

* 首先从任意的某个先验分布，比如Uniform分布或者高斯分布中，随机采样一个初始样本$$x_0 \sim \pi(x)$$
* 利用如下公式逐渐将样本像$$p(x)$$的高密度区域靠近：

$$ x_{i+1} \leftarrow x_i + \epsilon \nabla_x log p(x_i) + \sqrt{2 \epsilon} z_i, \  \text{where} \  z_i \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), i=1,2,\cdots, K$$

* 当步长$$\epsilon \rightarrow 0, K \rightarrow \infty$$时，$$x_k \sim p(x)$$

在实际操作中，使用训练好的score function model $$s_{\theta}(x)$$替代上面的$$\nabla_x log p(x)$$，并且取足够小的$$\epsilon$$采样足够多次，这样就可以保证在某次之后的采样值，均服从$$p(x)$$分布。这个过程就叫做Langevin采样。

**4). score matching**

朗之万采样解决了我们在有了score之后，该如何采样样本，使其服从$$p(x)$$分布的问题，而最重要的是如何获取score呢？score-based model的方法是训练一个score-based model来逼近score。训练方法如下所述。

首先写出损失函数（目标函数）。score-based model和似然函数模型类似，也是将最小化模型和数据分布之间的Fisher divergence作为训练的目标：

$$\mathop{\mathbb{E}}_{p(x)} \left[ \lVert \nabla_x log p(x) - s_{\theta}(x) \rVert_2^2 \right] = \int p(x) \lVert \nabla_x log p(x) - s_{\theta}(x) \rVert_2^2 dx$$

但$$p(x)$$是未知的，所以上述式子无法计算，所以实际上，是利用经验分布$$p_{data}(x)$$（即从数据中获得的分布）来代替真实分布$$p(x)$$来计算的，从而我们的目标函数如下：

$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right] = \int p_{data}(x) \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 dx$$

经验分布和真实分布的差别可以看[这篇博客](https://blog.csdn.net/qq_44638724/article/details/120242712)

而基于上述目标函数，使得模型的score-function与根据数据得到的经验分布的score相matching的算法，就叫做score-matching算法。

首先，我们简化一下上述目标函数：

$$
\begin{align}
& \mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right] \propto \frac{1}{2} \mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert s_{\theta}(x) - \frac{\partial log p_{data}(x)}{\partial x} \rVert_2^2 \right] \\
&= \frac{1}{2} \int p_{data}(x) \left[ \Vert s_{\theta}(x) \rVert_2^2 + \lVert \frac{\partial log p_{data}(x)}{\partial x} \rVert_2^2 - 2(\frac{\partial log p_{data}(x)}{\partial x})^Ts_{\theta}(x) \right] dx
\end{align}
$$

而

$$
\begin{align}
& \int p_{data}(x) \left[- 2(\frac{\partial log p_{data}(x)}{\partial x})^Ts_{\theta}(x) \right] dx = -2 \int p_{data}(x) (\sum_{i=1}^N \frac{\partial log p_{data}(x)}{\partial x_i})s_{\theta}(x)_i) dx \\
&= -2 \sum_{i=1}^N \int p_{data}(x) \frac{1}{p_{data}(x)} \frac{\partial p_{data}(x)}{\partial x_i} s_{\theta}(x)_i dx = -2 \sum_{i=1}^N \int \frac{\partial p_{data}(x)}{\partial x_i} s_{\theta}(x)_i dx \\
&= -2 \sum_{i=1}^N \int (\frac{\partial(p_{data}(x) s_{\theta}(x)_i)}{\partial x_i} - p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i}) dx = -2 \sum_{i=1}^N (p_{data}(x) s_{\theta}(x)_i \vert_{-\infty}^{\infty} - \int p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i} dx) \\
&= 2 \sum_{i=1}^N \int p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i} dx = 2 \int \sum_{i=1}^N p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i} dx = 2 \int p_{data}(x) tr(\frac{s_{\theta}(x)}{\partial x})dx
\end{align}
$$

其中$$N$$是输入$$x$$的维度。

回到之前的目标函数，可以发现，$$\lVert \frac{\partial log p_{data}(x)}{\partial x} \rVert_2^2$$与$$\theta$$无关，从而，之前的目标函数可以简化为：

$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$

目标函数得到了简化，但是如果表示$$s_{\theta}(x)$$的网络很深，$$x$$的维度很大的时候，计算$$tr(\frac{s_{\theta}(x)}{\partial x})$$仍然非常的繁重，在实际代码里部署起来很困难，从而在NCSN那篇论文里，又提出了两种更进一步的改进方法

**改进一：sliced score matching（由宋飏于2019年提出）**

在计算目标函数的时候，我们需要计算矩阵$$\frac{s_{\theta}(x)}{\partial x}$$的迹，而对于矩阵迹的估计，恰好有一种技巧：Hutchinson Trace estimation。

其具体做法是，对于一个随机向量$$v \in \mathbb{R}^n$$，如果其协方差矩阵为$$I$$，均值为$$\mathbf{0}$$，那么对于任意矩阵$$A \in \mathbb{R}^{n \times n}$$，$$tr(A) = tr(A \mathbb{E}(vv^T)) = \mathbb{E}(tr(A v v^T)) = \mathbb{E}(tr(v^T A v)) = \mathbb{E}(v^T A v)$$，从而将求矩阵$$A$$的迹，变成了求标量$$v^TAv$$对$$v$$的期望。

从而将上述技巧用到上述目标函数里，$$tr(\frac{s_{\theta}(x)}{\partial x}) = \mathbb{E}(v^T \frac{s_{\theta}(x)}{\partial x} v) = \mathbb{E}(v^T \frac{v^T s_{\theta}(x)}{\partial x})$$，目标函数则变为：

$$\mathop{\mathbb{E}}_{p(v), p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + v^T \frac{v^T s_{\theta}(x)}{\partial x} \right]$$

而计算$$\frac{v^T s_{\theta}(x)}{\partial x}$$只需要计算$$N$$次（相较于之前的$$N^2$$次，减少了很多），但引入了一个新的期望需要进行采样估计，如果$$N$$很大的时候，这样的做法是有效的。

**改进二：denoising score matching（NCSN那篇论文里的方法）**

这个方法也是为了避免计算$$tr(\frac{s_{\theta}(x)}{\partial x})$$，但它直接回到了最初的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right]$$，对于未知的$$p_{data}$$，其如果仅出现在求期望的概率分布上，并不出现在被求期望的值里面的时候，还是好办的，因为其就是经验概率分布，所以就是将所有的真实数据对应的被求期望的值加起来除以总数据数就行了（这也是为什么简化了的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$可以计算的原因，这个目标函数的问题只是在于它太难算了）。但是如果$$p_{data}(x)$$同时也出现在了被求期望的值的内部，就不能按照上述方法算了，而如果我们回到了最初的目标函数，那么该目标函数的被求期望的值里就含有$$p_{data}(x)$$，所以需要想另一种办法解决这个问题，而denoising score matching的办法就是：既然$$p_{data}(x)$$未知，就自行定义一个已知的数据分布$$q_{\sigma}$$（比如高斯分布），而且假设这个分布是在$$p_{data}$$上加噪声得来的。

具体来说，记原数据为$$x$$，加噪之后的数据为$$\tilde{x}$$，我们定义$$q(\tilde{x} \vert x) = \mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$，而且$$\sigma$$是已知的固定参数。从而$$q_{\sigma}(\tilde{x}) = \int q_{\sigma}(\tilde{x} \vert x) p_{data}(x) dx$$。我们希望用$$q_{\sigma}(\tilde{x})$$的score来近似$$p_{data}(x)$$的score（在$$\sigma$$很小的时候，它们是很相近的）。

那么对于这个新的数据$$\tilde{x}$$来说，其score-matching的目标函数就是:

$$\mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x}) - s_{\theta}(\tilde{x}) \rVert_2^2 \right]$$

这个式子可以显式的计算对于$$\tilde{x}$$score-matching算法的目标函数的值（因为$$q_{\sigma}(\tilde{x})$$显式的给定了），所以它叫做explicit score matching（ESM）。

$$\textbf{ESM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right] - 2 \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x}) \rangle \right] + c_1, \  \text{where} \  c_1 \  \text{is} \  \text{irrelavant} \   \text{w.r.t.} \  \theta$$

再定义一个denoising score matching（DSM）：

$$
\begin{align}
\textbf{DSM} &= \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right] - 2 \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) \rangle \right] + c_2, \  \text{where} \  c_2 \  \text{is} \  \text{irrelavant} \   \text{w.r.t.} \  \theta
\end{align}
$$

而我们发现，$$\textbf{ESM}$$的第一项和$$\textbf{DSM}$$的第一项相等：

$$\mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \int_{\tilde{x}} q_{\sigma}(\tilde{x}) \lVert s_{\theta}(\tilde{x}) \rVert_2^2 d \tilde{x} = \int_{\tilde{x}} \int_{x} q_{\sigma}(\tilde{x} \vert x) p_{data}(x) \lVert s_{\theta}(\tilde{x}) \rVert_2^2 d \tilde{x} dx =  \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right]$$

以及$$\textbf{ESM}$$的第二项和$$\textbf{DSM}$$的第二项也相等：

$$
\begin{align}
\mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x}) \rangle \right] &= \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \langle s_{\theta}(\tilde{x}), \frac{\partial log q_{\sigma}(\tilde{x})}{\partial \tilde{x}} \rangle \right] = \int_{\tilde{x}} q_{\sigma}(\tilde{x}) \langle s_{\theta}(\tilde{x}), \frac{\partial log q_{\sigma}(\tilde{x})}{\partial \tilde{x}} \rangle d \tilde{x} = \int_{\tilde{x}} q_{\sigma}(\tilde{x}) \langle s_{\theta}(\tilde{x}), \frac{1}{q_{\sigma}(\partial \tilde{x})}\frac{\partial q_{\sigma}(\partial \tilde{x})}{\tilde{x}} \rangle d \tilde{x}\\
&= \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \frac{\partial q_{\sigma}(\partial \tilde{x})}{\partial \tilde{x}} \rangle d \tilde{x} = \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \frac{\partial}{\partial \tilde{x}} \int_x q_{\sigma}(\tilde{x} \vert x) p_{data}(x) dx \rangle d \tilde{x} = \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \int_x \frac{\partial q_{\sigma}(\tilde{x} \vert x)}{\partial \tilde{x}} p_{data}(x) dx \rangle d \tilde{x}\\
&= \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \int_x \frac{\partial log q_{\sigma}(\tilde{x} \vert x)}{\partial \tilde{x}} q_{\sigma}(\tilde{x} \vert x) p_{data}(x) dx \rangle d \tilde{x} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) \rangle \right]
\end{align}
$$

从而惊讶地发现，ESM和DSM只相差了一个与$$\theta$$无关的常数。从而现在可以用DSM来替代ESM作为优化基于$$\tilde{x}$$的score-matching的目标函数了，也就是说，之前我们引入$$q_{\sigma}(\tilde{x})$$的score来近似$$p_{data}(x)$$的score，现在我们可以用$$q_{\sigma}(\tilde{x} \vert x)$$的score来近似$$p_{data}(x)$$的score了。而根据我们的假设，$$q_{\sigma}(\tilde{x} \vert x)$$就是一个高斯分布$$\mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$，从而其score是可以closed-form计算出来的，也就是说，现在的目标函数变为：

$$\textbf{DSM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{x-\tilde{x}}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{-\epsilon}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right], \  \text{where} \  \epsilon \sim \mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$

从而我们要做的就是，对于每个输入数据$$x$$，从$$\mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$中采样噪声$$\epsilon$$，加到$$x$$上得到$$\tilde{x}$$，作为$$s_{\theta}$$的输入，然后优化上述目标函数，即DSM。也就是说，$$s_{\theta}$$实际上建模的是真实数据和加噪之后数据的差值（即噪声）。

综上，我们从概率分布的表示、估计到采样的过程基本已经完成了，整个“Score-based generative modeling”的过程可以总结如下图:

![5]({{ '/assets/images/diffusion_5.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[DiffusionModel-NCSN原理与推导](https://zhuanlan.zhihu.com/p/670052757)*

最后，再介绍一下score-based models的几个主要的问题。


**5). score-based models的几个主要问题**

尽管score-based models根据上述所说，具有完整的训练和采样过程（由score matching来对目标函数进行训练，由朗之万采样利用训练好的score function来对数据进行采样），但其在实际应用中有以下几个主要的困难：

* 目标函数难以优化，即loss难以收敛
* score matching算法对$$p_{data}(x)$$的score估计不准确
* 最终采样得到的数据，与训练数据的分布偏差较大

下面我们依次来看看这些问题并分析其原因。

**问题一：loss不易收敛**

如果我们采用sliced score matching方法，将简化后的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$，改进为$$\mathop{\mathbb{E}}_{p(v), p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + v^T \frac{v^T s_{\theta}(x)}{\partial x} \right]$$，记为SSM loss，并对其进行优化，那么在实际操作中，该loss的变化趋势如下左图所示：

![6]({{ '/assets/images/diffusion_6.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[DiffusionModel-NCSN原理与推导](https://zhuanlan.zhihu.com/p/670052757)*

可以看到，SSM loss非常抖动。

为了解释这个现象，首先需要了解流行假设（manifold hypothesis）。

流行假设认为，生活中的真实数据大部分都倾向于分布在某个低维空间中（即用某几个自由参数就可以表示该空间）。也就是说，尽管针对数据的编码空间（比如说通过神经网络将数据表示为某种feature）的维度可能很大，但实际上该编码（feature）在很多维度上都存在信息冗余，所以实际上我们可以用更小的编码空间来表示这些数据，这说明实质上，这些数据仅仅分布在该高维编码空间的某个低维流形当中，并没有“占满”整个编码空间。

回到score-basde model上来，我们的数据同样也是位于某个低维流形之上（如果是图片的话，原始的编码空间即是像素空间，即$$\left[0,255\right]^{H \times W \times 3}$$），也就是说，数据并没有充满整个$$p(x)$$，即$$p_{data}(x)$$在很多$$x$$上是没有数据的，这就导致了在使用$$p_{data}(x)$$作为替代$$p(x)$$的真实分布的时候，这些$$x$$上的score是无法获得的。

> 而我们确实是需要使用$$p_{data}(x)$$来替代$$p(x)$$作为真实的数据分布，因为$$p(x)$$是完全无法知道的，我们有的只有数据！

而且对于sliced score matching，我们还将原始的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$，简化为了$$\mathop{\mathbb{E}}_{p(v), p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + v^T \frac{v^T s_{\theta}(x)}{\partial x} \right]$$，该简化过程根据之前的推导，需要假设$$\lim_{x \rightarrow -\infty} p_{data}(x) = \lim_{x \rightarrow \infty} p_{data}(x) = 0$$，而着同样需要假设$$p_{data}(x)$$能够在整个编码空间上都有数据。

**问题二：score的估计不准确**

score的估计不准确，分为两个层面的不准确，首先是score function $$s_{\theta}(x)$$对于$$p_{data}(x)$$的score估计不准确，其次是$$s_{\theta}(x)$$对于真实分布$$p(x)$$的估计不准确。

对于后者来说，对于$$p(x)$$较小的区域，即概率密度较低的区域，数据集里位于该区域的数据数量会很少，甚至没有，这样的话，使用$$p_{data}(x)$$对$$p(x)$$进行近似的时候，在这些区域的近似就不准确。从训练的角度来说，score-based model在这些区域的值相对于真实的$$p(x)$$的score来说就估计的不准确（因为在这些区域，$$p_{data}(x)$$和$$p(x)$$的score本身就有较大的偏差，所以并不是score-matching算法或者是目标函数的问题，这是使用经验分布来替代真实分布造成的问题）。

而对于前者来说，从损失函数的角度来分析，损失函数为$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right]$$，对于$$p_{data}(x)$$较小的区域，那么$$\lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2$$会乘上一个较小的$$p_{data}(x)$$权重，从而在整个loss里，这一项的比重很小，就会导致训练的时候不会关注这个区域，也就训练不充分，从而导致这个区域内的$$s_{\theta}(x)$$与$$\nabla_x log p_{data}(x)$$差异较大。

![8]({{ '/assets/images/diffusion_8.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[基于梯度去噪的分数模型：NCSN(Noise Conditional Score Networks)](https://zhuanlan.zhihu.com/p/597490389)*

对于上面图来说，左侧是$$p_{data}(x)$$的scores，右侧是训练好的模型，也就是score function，$$s_{\theta^{\ast}}(x)$$，其中深色的部分表示数据density大的部分，而红色框内部，则表示
$$p_{data}(x)$$的scores和$$s_{\theta^{\ast}}(x)$$相近的区域。可以看到，在density较低的区域，这两个scores是不相近的。


**问题三：生成结果偏差大**

如果分数估计不准，即$$s_{\theta}(x)$$与$$\nabla_{x} p(x)$$的偏差较大，那么一个直接的结果就是使用朗之万采样得到的新生成数据和数据集里的数据差异较大，即生成数据的分布，并不符合$$p(x)$$或者由数据集得到的经验分布$$p_{data}(x)$$。这是因为，对于朗之万采样过程来说，起始点很有可能会选择在一个低密度区域内，而由之前所说，低密度区域内$$s_{\theta}(x)$$不准确，从而导致每一步的方向都是不准确的，那么就很难保证更新后的采样点落在$$p(x)$$或者$$p_{data}(x)$$的高密度区域内。

另外一个令人惊讶的结果是，即使$$s_{\theta}(x)$$是准确的，即非常接近$$\nabla_x log p(x)$$，甚至直接用ground truth的$$\nabla_x log p(x)$$来作为朗之万采样的score，如果真实的数据分布$$p(x)$$是由多个分布按一定比例混合而成的，那么使用朗之万采样算法采样得到的结果，也不能反应各个分布之间的比例关系，下图给了一个例子：

![9]({{ '/assets/images/diffusion_9.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

上面的例子里，数据是由两个二维高斯分布混合而成的，左图是实际的数据分布$$p_{data}(x)$$，右图是根据真实的$$p(x)$$经过朗之万采样得到的数据分布。可以看到，朗之万采样的数据，并不能反映这这两个高斯分布在混合分布里所占的比例。

具体原因是，假设混合分布为$$p(x) = a p_1(x) + (1-a)p_2(x)$$，那么$$\nabla_x log p(x) = \nabla_x log p_1(x) + \nabla_x log p_2(x)$$，丢失了比例信息$$a$$。

> 实际上，如果朗之万采样算法里的步长$$\epsilon$$取得足够的小，时间$$T$$足够的长，那么实际上其采样值是可以逼近任意的数据分布的（包括混合分布），但是实际操作中，这两个值都是有限制的，就会导致上述的问题的发生。


而上述的三个问题，均可以用noise-conditioned score network（NCSN）解决。


### (2). NCSN

noise-conditioned score network是分数模型的一种

**训练目标：**

使用不同强度（不同方差）零均值的采样的高斯噪声对原数据进行加噪（扰动），然后使用**同一个网络**，对加了不同级别**噪声的数据的分布的分数**，进行估计，这个网络的输入是加了噪声的数据，**以及噪声强度指示**。注意，是对加了噪声的数据分布的分数进行估计，而并不是对原数据分布的分数进行估计（因为做不到）。而在网络训练好了之后，对于加上强度足够小的噪声的数据的分布的分数，就近似于原数据的分布的分数。

**采样生成**

使用退火（annealing）朗之万方法使用score来采样。退火朗之万采样实际上就是在噪声强度递减的模式下进行朗之万采样。

NCSN是如何破解之前提到的score-based models的三个问题的：

* NCSN使用高斯噪声去扰动数据，而高斯噪声是弥散在整个编码空间中的，因此扰动后的数据就不在低维流形中了，从而score-matching算法就可以较好的训练$$s_{\theta}(x)$$去近似$$p_{data}(x)$$了。
* 在加上高斯噪声扰动数据时，尺度较大的噪声有希望将原数据从$$p(x)$$较高的区域转移到$$p(x)$$较低的区域，从而对低密度区域的数据也有了更多的训练。在低密度区域的数据量也增大之后，即使在朗之万采样的时候，初始值取在了低密度区域，但因为这个时候低密度区域也得到了良好的训练，所以$$s_{\theta}(x)$$在该区域的值也接近$$\nabla_x log p_{data}(x)$$的值，从而也可以在采样很多次后，到达高密度区域，也就是生成和原数据分布相似的图片。

NCSN是一类分数模型，所以之前所说的分数模型的目标函数，score-matching算法，以及在获得score function之后使用朗之万采样获取新数据的过程是一样的，但NCSN有另外的改进来缓解之前所说的score-based models的问题，下面我们具体来介绍这些改进的细节。

**1). 噪声设计原理**

NCSN使用了denoising score matching的方式来优化目标函数。按照之前所说的，对于每个输入的原数据$$x$$，我们对它加上一个噪声从而获得一个新的数据$$\tilde{x}$$，其分布满足：$$q(\tilde{x} \vert x) = \mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$，其中$$\sigma$$是我们需要重点考虑的问题。

在NCSN中，我们实际上不仅仅考虑一个$$\sigma$$，而是考虑一系列的$$\sigma_i, i=1,2, \cdots, L$$，也就是说，对于一个数据$$x$$，会给他加上从不同的$$\mathcal{N}(\textbf{0}, \sigma_i^2 \textbf{I})$$里采样的噪声，得到一系列加噪的新数据$$\tilde{x}_i, i=1,2,\cdots, L$$。

那么，为什么要选择不同强度的噪声呢？

因为如果只选择一个的话，那么因为我们需要填充低密度区域，使得$$p_{data}(x)$$在这些区域也能有值，而且需要摆脱低维流形假设，那么$$\sigma^2$$就不能太小。但是另一方面，如果$$\sigma^2$$很大的话，从$$q_{\sigma}(\tilde{x} \vert x) = \mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$可以看出，我们所采样的$$\tilde{x}$$就可能和$$x$$差距较大了，那这种情况下，用$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$来近似$$\nabla_{x} log p_{data}(x)$$就不合理了。

正是由于上述的这个矛盾，所以我们考虑一系列尺度的噪声，方差由大到小：$$\lbrace \sigma_i^2 \rbrace_{i=1}^L$$，并且满足$$\sigma_1 / \sigma_2 = \sigma_2 / \sigma_3 = \cdots = \sigma_{L-1} / \sigma_L > 1$$。并且$$\sigma_1$$要足够大，满足填充低密度区域且摆脱低维流形假设的需求，而$$\sigma_L$$要足够小，满足可以使用$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$来近似$$\nabla_{x} log p_{data}(x)$$的需求。

**2). score拟合网络的设计**

由于我们需要生成的数据和原输入数据具有相同的尺寸，所以选择U-Net作为网络的主体。输入是加了噪声之后的数据$$\tilde{x}$$，以及当前所加的噪声满足的高斯分布的方差$$\sigma$$，输出是对该加了噪声之后的数据$$\tilde{x}$$所满足的分布的对数的梯度的近似，即$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$。

而在有了网络结构，以及网络的输入输出之后，我们就可以考虑该如何训练这个网络了，NCSN采用的是denoising score matching算法。由之前的结果可知，对于单个噪声$$\mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$，损失函数是DSM：

$$\textbf{DSM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{x-\tilde{x}}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{-\epsilon}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right], \  \text{where} \  \epsilon \sim \mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$

也就是：

$$\mathcal{L}(\theta, \sigma) = \textbf{DSM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{x-\tilde{x}}{\sigma^2} - s_{\theta}(\tilde{x}, \sigma) \rVert_2^2 \right]$$

从而对于一系列的噪声$$\lbrace \sigma_i^2 \rbrace_{i=1}^L$$，网络的损失函数定义为：

$$\mathcal{L}(\theta, \lbrace \sigma_i^2 \rbrace_{i=1}^L) = \frac{1}{L} \sum_{i=1}^L \lambda_i (\sigma_i) \mathcal{L}(\theta, \sigma_i)$$

其中$$\lambda_i(\sigma_i)$$是依赖于$$\sigma_i$$的超参数，$$i=1,2,\cdots,L$$。

作者根据经验发现，在网络训练收敛之后，$$\lVert s_{\theta}(\tilde{x}, \sigma) \rVert_2$$的量级在$$\frac{1}{\sigma}$$附近，而作者希望所有的加权后的损失$$\lambda_i (\sigma_i) \mathcal{L}(\theta, \sigma_i)$$都有着差不多的量级，与$$\sigma_i$$的取值无关，从而设置$$\lambda_i = \sigma_i^2$$，从而：

$$\mathcal{L}(\theta, \lbrace \sigma_i^2 \rbrace_{i=1}^L) = \frac{1}{L} \sum_{i=1}^L \lambda_i (\sigma_i) \mathcal{L}(\theta, \sigma_i) = \frac{1}{L} \sum_{i=1}^L \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert s_{\theta}(\tilde{x}_i, \sigma_i) + \epsilon_i \rVert_2^2 \right]$$

其中$$\epsilon_i \sim \mathcal{N}(\textbf{0}, \textbf{I})$$，$$\tilde{x}_i = x + \sigma_i \epsilon_i$$，$$i=1,2,\cdots, L$$。

> 这里的$$s_{\theta}$$的输入除了被扰动的数据$$\tilde{x}$$以外，还需要所加噪声对应高斯分布的方差作为输入，和之前DDPM里不仅需要$$x_t$$作为网络的输入，还需要$$t$$作为网络的输入，是等价的。

> 这里的$$s_{\theta}(\tilde{x}, \sigma)$$实际上是拟合了$$-\epsilon$$，也就是拟合了采样的噪声，和DDPM里$$\mu(x_t, t)$$实际上也是拟合了加在$$x_0$$上得到$$x_t$$的噪声$$\bar{\epsilon}_t$$是等价的。同样的，这里的噪声也是需要取多个强度的，也就是说，$$s_{\theta}$$也需要拟合多个强度的噪声。


**4). 采样方法：退火朗之万采样（annealing Langevin dynamics**

![10]({{ '/assets/images/diffusion_10.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

### (3). 一些补充说明

**去噪生成**

正如前面所说，NSCN实际上就是在做基于梯度的去噪生成。$$\tilde{x} = x + \sigma \epsilon$$，从而$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) = -\frac{\epsilon}{\sigma}$$，也就是说，我们希望网络基于输入$$\tilde{x}, \sigma$$所需要学习的$$q_{\sigma}(\tilde{x} \vert x)$$的分数，即$$s_{\theta}(\tilde{x}, \sigma) = \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$，**与所加噪声的方向相反**（注意$$\tilde{x}, x, \epsilon$$都是高维数据，可以近似地看作高维向量）。因此，在采样生成的时候，沿着分数的方向走，就是沿着噪声的反方向走，这样就能够最终回到最初的未加上噪声的样本，也就是去噪！

**与DDPM的关系**

NCSN和DDPM一样，本质都是去噪，前者是隐式的，后者是显式的，NCSN所用的denoising score matching算法所使用的目标函数DSM，实际上就是在预测噪声，而DDPM的反向扩散过程，就是希望模型直接预测所加的噪声。

**关于DDPM和NCSN的总结**

生成模型的本质，就是对数据的概率密度分布进行拟合，从而实现采样。而如何表示概率分布，不同模型有不同的办法，可被分为两种范式：（1）对数据的采样过程建模；（2）对数据的概率密度建模。前者并不纠结于数据分布的概率密度，而是通过其他方式达到表示概率分布的目的，因此被称为隐式模型（implicit）。而后者直接让模型估计概率密度，于是被称为显式模型（explicit）。

隐式模型里最有名的就是GAN，其对网络框架没有限制，但是其训练不稳定，无法计算似然函数，并且没有一个统一的标准来衡量模型的优劣。

显式生成模型包括贝叶斯网络（比如VAE），马尔可夫随机场，自回归模型，flow models等，这类模型也叫做似然模型，其通过最大似然的方式来学习数据分布。这类模型的首要优点是可以计算似然，从而能够很容易的衡量模型的优劣，但是使用一般的energy-based模型来表示概率，需要归一化参数，这限制了模型的灵活性（因为需要选择能够学习归一化参数的模型框架）。

从本质上来说，DDPM也是显式生成模型，其可以看作级联的VAE，其使用的训练目标也是极大似然，并且其对似然函数的处理方式也类似于VAE里的变分推理法。但是DDPM在扩散的过程中，每一步都走的很小，这样使得模型的训练更加容易以及稳定，从而效果会更好，但付出了时间长的代价。

而分数模型则与之前所说的生成模型都不一样，其是估计数据分布的对数的梯度（即score），利用所估计的score使用朗之万采样获取新数据。而NCSN是分数模型的一种，其通过给数据加上不同强度的噪声，然后训练网络去联合估计加噪后的数据分布的score，来使得网络能够近似原未加噪数据的score。

> 这里的联合估计，指的是对于加上了不同级别噪声的数据的分数，用同样的一个网络去估计。而且注意，网络估计的是加噪的数据分布的分数，并不是原始数据分布的分数，原始数据分布的分数在网络经过充分的学习之后可以进行近似。

**参考文献**
1. https://yang-song.net/blog/2021/score/
2. https://zhuanlan.zhihu.com/p/670052757
3. https://zhuanlan.zhihu.com/p/662633920
4. https://zhuanlan.zhihu.com/p/597490389


## 3. StableDiffusion

StableDiffusion，出自于CVPR2022的这篇论文：[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/pdf/2112.10752)。作为当下最出圈的扩散模型之一，StableDiffusion具有图像生成效果更好、训练速度更快、可以根据输入的文本生成图像等优点。而且，利用预训练好的StableDiffusion模型来进行各种下游任务更是如今一个热门方向，所以了解StableDiffusion的原理充分且必要。

StableDiffusion也是一种扩散模型，但其相比较于一般的扩散模型，主要有三个区别：（1）采样空间从像素空间变成了feature空间，所以网络需要增加一个从图像到feature的Encoder，以及从feature到图像的Decoder；（2）允许根据输入文本进行图像生成，且生成的图像语义信息和输入文本相匹配。其具体实现是在扩散模型原本的U-Net结构基础上，增加了multi-head attention mechanism。下面就根据这两个改动来介绍StableDiffusion的原理。

如下，是StableDiffusion采样（即生成新数据）的过程：

![11]({{ '/assets/images/diffusion_11.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

由流程图可以看到，输入的文本（例子里是An astronout riding a horse）经过一个freezed的text feature extractor获取embedding（是利用CLIP模型预训练好的，这样可以保证和图像特征的语义一致性）。而初始的特征是从标准高斯分布里采样的一个$$64 \times 64$$的feature，其和text embedding一起喂给一个text conditioned latent UNet，得到更新的feature，再和text embedding一同喂给该UNet，如此重复$$N$$次，最终的feature，经过一个variational autoencoder Decoder，得到输出图像，即为去噪后的生成图像。

### (1). 改进一：在feature层面上做diffusion，而不在像素层面上

StableDiffusion在原论文里的名字叫做latent diffusion model（LDM），而latent就表明这个扩散过程是在latent的feature上进行的，而并非在原图像空间上。这样做，可以大大加快StableDiffusion的速度，毕竟feature space的维度要比图像空间维度小很多，且一定程度上可以缓解低维流形假设带来的影响。

StableDiffusion的框架里，有一个encoder，将原图片压缩到低维的latent feature上，还有一个decoder，对于latent code的输入，reconstruct到图片空间上。而在encoder将图片映射到latent feature上之后，便在latent feature上做扩散过程：

![12]({{ '/assets/images/diffusion_12.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}



### (2). 改进二：通过在U-Net结构里引入multi-heads attention mechanism来允许文本指导图片生成

为了允许扩散模型能根据输入文本生成语义匹配的图片，需要在反向扩散过程，即从噪声生成图片的过程中，将原先的只接受加噪图片（训练过程）或者噪声（采样过程）以及时间$$t$$的UNet，改为还能够再接受一个text embedding作为输入，而要作此改动，并且需要让图片的features能够学会对应的文本embedding里的语义信息，则需要将UNet改造为含有attention模块的新结构，attention模块就可以用来在图片的features和文本的embedding之间学习信息。

加了文本condition的StableDiffusion的反向扩散过程如下：

![13]({{ '/assets/images/diffusion_13.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

而具体来看改进后的UNet结构，则是如下图所示：

![14]({{ '/assets/images/diffusion_14.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

UNet新增加的多头注意力机制$$\textbf{Attention}(Q,K,V)$$的原理如下（以最右边的第一个模块为例）：

$$\textbf{Attention}(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d}})V$$

其中$$Q = W_Q z_T$$，$$K=W_K \tau_{\theta}(y)$$，$$V = W_V \tau_{\theta}(y)$$，其中$$W_Q, W_K, W_V$$是三个矩阵，也就是该注意力模块里需要被学习的参数。

图里的switch的作用是：

* 如果输入的是文本，那么$$\tau_{\theta}$$就是某种text embedding extractor，比如预训练的CLIP或者BERT，获取了text embedding之后，和feature $$z_t$$计算cross-attention。
* 如果输入的是其它的可以和图片spatially aligned的输入，比如说semantic maps，images，inpaintings等， 那么$$\tau_{\theta}$$就变成了其它对应的feature extractor，而得到的feature也不再与图片feature进行cross attention计算了，而是直接concatenate起来输入给UNet来获取图片feature $$z_t$$的更新输出$$z_{t-1}$$。

### (3). StableDiffusion的训练和采样

**训练**

StableDiffusion的训练数据是图片文本对，且每一对数据语义信息相同。

类似于DDPM的推导，我们可以直接写出LDM（也就是StableDiffusion）的训练loss如下：

$$
\begin{align}
z_0 &= \textbf{Encoder}(x_0) \\
z_t &= \sqrt{\bar{\alpha}_t} z_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \  \text{where} \  \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I}) \\
\mathcal{L}_{LDM} = \mathop{\mathbb{E}}\limits_{t \sim \left[2, T \right], (x_0,y) \sim q(x_0,y), \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ \lVert \epsilon - f_{\phi}(z_t, t, \tau_{\theta}(y)) \rVert_2^2 \right]
\end{align}
$$

其中$$(x_0, y)$$是输入图片文本对，$$\tau_{\theta}$$是freezed的text embedding extractor，$$f_{\phi}$$是我们的UNet。

和DDPM的训练目标函数相比，只有两点区别：

* 引入了encoder来将输入图片映射到feature空间上
* UNet的输入增加了text embedding


**采样**

StableDiffusion的采样过程如下：

![15]({{ '/assets/images/diffusion_15.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}


### (4). 一些补充说明

**DDPM和LDM的对比**

普通的DDPM流程图：

![16]({{ '/assets/images/diffusion_16.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}


LDM流程图：

![17]({{ '/assets/images/diffusion_17.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}


**带有多头注意力机制的UNet的具体架构设计**

参考下面的参考资料里4，5，6三个博客内容。


**参考资料**
1. https://medium.com/@steinsfu/stable-diffusion-clearly-explained-ed008044e07e
2. https://andrewkchan.dev/posts/diffusion.html
3. https://zhuanlan.zhihu.com/p/582266032
4. http://blog.cnbang.net/tech/3823/
5. https://blog.csdn.net/xd_wjc/article/details/134441396
6. https://zhuanlan.zhihu.com/p/582266032


## 4. [DreamFusion](https://dreamfusion3d.github.io/)：开启了使用预训练好的2D diffusion模型获取3D representation的先河

DreamFusion原论文的全名是DreamFusion: Text-to-3D using 2D Diffusion，荣获了ICLR2023的outstanding paper award，同时也成为后续大量科研工作的baseline，其通讯作者Ben Mildenhall就是NeRF的一作，而三作Jonathan T. Barron，更是3D领域的重量级。

原论文没有给code implementation，但有大佬公布了[re-implement的GitHub仓库](https://github.com/ashawkey/stable-dreamfusion)。

![18]({{ '/assets/images/diffusion_18.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

文章里的这句话很精髓，直接引用：

> We are not interested in sampling pixels; we instead want to **create 3D models that look like good images when rendered from
random angles**. Such models can be specified as a differentiable image parameterization (DIP), where a differentiable generator $$g$$ transforms parameters $$\theta$$ to create an image $$x = g(\theta)$$. DIPs allow us to express constraints, optimize in more compact spaces (e.g.~arbitrary resolution coordinate-based MLPs), or leverage more powerful optimization algorithms for traversing pixel space. For 3D, we let $$\theta$$ be parameters of a 3D volume and $$g$$ a volumetric renderer. To learn these parameters, we require a loss function that can be applied to diffusion models.

DreamFusion是第一个（应该是？）利用pre-trained好的2D diffusion model来获取3D representation的论文，其想法和思路都很直接：对于一个已经预训练好的2D diffusion model，以及一个文字输入，其能够生成满足该文字语义的图片。从而我们可以初始化一个3D representation（在DreamFusion里就是一个NeRF），每次随机sample一个viewpoint，结合NeRF渲染出这个角度的图片，该图片需要与文字输入相匹配，如何利用pre-trained的diffusion model来衡量这种匹配值，是关键，DreamDiffusion提出了Score Distillation Sampling（SDS）来约束这个匹配值，下面就来具体介绍这个SDS的细节。

首先，不管是DDPM还是NCSN，其训练的loss，记为$$\mathcal{L}_{diff}$$都可以写为如下形式：

$$\mathcal{L}_{diff}(\phi) = \mathop{\mathbb{E}}\limits_{x \sim q(x), t \sim \left[2, T \right], \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ w(t) \lVert f_{\phi}(\alpha_t x + \sigma_t \epsilon) - \epsilon \rVert_2^2 \right]$$

也可以对于每个数据$$x \sim q(x)$$都定义一个$$\mathcal{L}_{diff}(\phi, x)$$，那么$$\mathcal{L}_{diff}(\phi) = \mathop{\mathbb{E}}\limits_{x \sim q(x)} \mathcal{L}_{diff}(\phi, x)$$。

其中$$w(t)$$是DDPM里的$$\frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2}$$，也是NCSN里的$$\lambda_t(\sigma_t)$$。

现在我们有了一个预训练好的diffusion model（即$$\phi$$是固定的），我们想要训练的是一个3D representation（即上面所说的$$g(\theta)$$）的参数（即$$\theta$$），使得对于其在任意视角下得到的新图片$$x = g(\theta)$$，最小化$$\mathcal{L}_{diff}(\phi, x=g(\theta))$$：

$$\theta^{\ast} = \arg\min\limits_{\theta} \mathcal{L}_{diff}(\phi, x=g(\theta)) = \arg\min\limits_{\theta} \mathop{\mathbb{E}}\limits_{t \sim \left[2, T \right], \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ w(t) \lVert f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t) - \epsilon \rVert_2^2 \right]$$

但实际上，用上述loss是无法得到一个好的3D representation结果的（在这篇文章里，$$g(\theta)$$就是NeRF）。甚至不考虑NeRF，直接让$$x$$变成被优化的目标（即$$g(\theta)$$是个identity map），按照上述loss也难以得到一个符合文本描述的图片$$x$$。文章里说有些research论文说如果仔细挑选timesteps，改变优化策略和训练策略是有可能得到好的结果的，但作者认为这样做太复杂了，而且太过于工程化，且不易推广到一般情况。

作者的做法是，换个新的loss。

首先，文章分析了为什么使用上述的loss，$$\mathcal{L}_{diff}(\phi, x=g(\theta))$$效果不好。计算该loss对$$\theta$$的导数：

$$\nabla_{\theta} \mathcal{L}_{diff}(\phi, x=g(\theta)) = \mathop{\mathbb{E}}\limits_{t \sim \left[2, T \right], \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ 2 \alpha_t w(t) (f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t, y) - \epsilon) \frac{\partial f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t, y)}{\partial (\alpha_t g(\theta) + \sigma_t \epsilon)} \frac{\partial g(\theta)}{\partial \theta} \right]$$

其中$$y$$是text embedding。最后一个表达式的期望表示式内部，有三项乘积组成（不考虑系数$$2 \alpha_t w(t)$$），其中第一项$$f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t, y) - \epsilon$$叫做noise residual，第二项$$\frac{\partial f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t, y)}{\alpha_t g(\theta) + \sigma_t \epsilon}$$叫做UNet Jacobbian，第三项$$\frac{\partial g(\theta)}{\theta}$$叫做generator Jacobbian。

作者发现，计算中间那项计算十分复杂（因为UNet结构复杂），并且会造成结果变差，所以不如去掉这项，从而得到了新的loss，记为$$\mathcal{L}_{SDS}(\phi, x=g(\theta))$$，这个新loss对于$$\theta$$的梯度，就是上述$$\mathcal{L}_{diff}$$对于$$\theta$$的梯度去掉了中间那项：

$$\nabla_{\theta} \mathcal{L}_{SDS}(\phi, x=g(\theta)) \triangleq \mathop{\mathbb{E}}\limits_{t \sim \left[2, T \right], \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ 2 \alpha_t w(t) (f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t, y) - \epsilon) \frac{\partial g(\theta)}{\theta} \right]$$

有其他文章给出了下面的结果：

$$\nabla_{\theta} \mathcal{L}_{SDS}(\phi, x=g(\theta)) = \nabla_{\theta} \mathop{\mathbb{E}}\limits_{t \sim \left[2, T \right], \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ 2\sigma_t w(t) \textbf{D}_{\textbf{KL}}(q(\alpha_t g(\theta) + \sigma_t \epsilon; g(\theta), y, t) \Vert p_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon; y, t)) \right]$$

其中$$q(\alpha_t g(\theta) + \sigma_t \epsilon; g(\theta), y, t)$$表示的是前向扩散过程在数据$$g(\theta)$$上加噪之后（即$$\alpha_t g(\theta) + \sigma_t \epsilon$$），该噪声数据的概率分布。而该结果是知道的，是一个高斯分布，也就是DDPM里的$$q(x_t \vert x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1 - \bar{\alpha}_t)\mathbf{I})$$。而$$p_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon; y, t)$$表示的是反向扩散过程，加了噪声的数据$$\alpha_t g(\theta) + \sigma_t \epsilon$$的分布，此时该分布的均值由网络预测出（输入是该噪声数据本身和时间$$t$$），同样也是一个高斯分布。

有了上述结果，就可以知道，$$\mathcal{L}_{SDS}(\phi, x=g(\theta))$$和$$\mathop{\mathbb{E}}\limits_{t \sim \left[2, T \right],  \epsilon \sim \mathcal{N}(\textbf{0}, \textbf{I})} \left[ 2\sigma_t w(t) \textbf{D}_{\textbf{KL}}(q(\alpha_t g(\theta) + \sigma_t \epsilon; g(\theta), y, t) \Vert p_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon; y, t)) \right]$$只差了一个和$$\theta$$无关的常数，从而知道了loss值，就可以观察loss变化趋势了。

由$$\mathcal{L}_{SDS}$$的表达式可以看到，其并不需要计算关于diffusion model的反向传播（只需要一个forward pass来计算$$f_{\phi}(\alpha_t g(\theta) + \sigma_t \epsilon, t, y)$$的值），所以diffusion model的作用是一个efficient, frozen critic that predicts image-space edits。

DreamFusion的流程图如下：

![19]({{ '/assets/images/diffusion_19.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

$$z_t$$就是我们加噪之后的数据，也就是之前公式里的$$\alpha_t g(\theta) + \sigma_t \epsilon$$，$$\hat{x}_{\phi}(z_t \vert y; t)$$是以$$z_t$$作为输入，经由diffusion models预测得到的输入数据，也就是该值需要近似$$g(\theta)$$，$$\hat{\epsilon}_t(z_t \vert y ; t)$$是diffusion models以$$z_t$$作为输入，预测得到的$$z_t$$所加上的噪声值，也就需要近似等于$$\epsilon$$。

现在已经知道了DreamDiffusion是如何使用一个预训练好的diffusion models，利用SDS loss来optimize一个NeRF的参数了。下面我们来看一下具体的实现细节。

**diffusion models的选取**

DreamFusion选择了一个使用图像文本对训练的可以根据输入文本生成语义一致的图片的diffusion models，叫做Imagen。其使用了basic的Imagen模型，即输出图像尺寸为$$64 \times 64$$，而且不对它做任何调整，只是拿来用。

**NeRF的选取和结构细节**

DreamFusion每次随即设置一个相机位置、相机旋转角度，来render一个新的view，然后按照上述所说的步骤来优化NeRF的参数。作者使用的是mip-NeRF 360（可能是因为其作者和DreamFusion的作者高度重合）。

传统的NeRF每次的输入是相机参数和一个3D坐标，输出是该点的opacity（或者叫volume density）$$\tau$$，用来衡量3D空间里该点位于物体的表面与否）以及emit radiance，也就是与相机视角相关的RGB值（opacity与相机视角无关）。而DreamFusion则是同样以相机参数和一个3D坐标为输入，输出的是该点的opacity和基于RGB的albedo（基于RGB的albedo和RGB的区别在于，其代表的是该点材料本身的颜色，与视角、光照等其他外界因素都没有关系）$$\rho$$，即：

$$(\rho, \tau) = \textbf{MLP}(\mu; \theta)$$

其中$$\mu$$是空间三维坐标，$$\theta$$是相机内参外参。

在有了每个三维点的albedo之后，还需要结合光照条件来得到最终relistic的该点的RGB值（这个过程叫做shading），而该点的shading，需要计算该点的normal vector（其表示该点的局部几何特征，即该点的normal是垂直于该点的切平面的）。而每个三维点的surface normal vector的计算如下：

$$n = -\nabla_{\mu} \tau / \lVert \nabla_{\mu} \tau \rVert$$

在有了每个点的albedo $$\rho$$，normal $$n$$，并且确定了点光源的三维位置$$l$$，点光源的颜色$$l_{\rho}$$，以及环境光颜色$$l_{a}$$之后，

每个三维点$$\mu$$的最终的color就可以计算出来了：

$$c = \rho (l_{\rho} \max(0, n \cdot (l-\mu) / \Vert l-mu \Vert) + l_a)$$

有了每个点的color $$c$$和opacity $$\tau$$之后，就可以像classical NeRF一样render图片了。

作者还发现，随机的将某些点的albedo直接替换成白色的，即$$(1,1,1)$$，能够更好的学习场景的texture。这还可以防止模型学到flat的geometry：比如说场景里有一副画了松鼠的画，以及有一个真实的三维松鼠，在某些很多相机角度下都能render出类似的图片。

作者还发现，需要限制NeRF的三维采样点的范围在一个球面内，并且利用另一个MLP来建模环境光，其输入是每个三维点相对于相机的ray direction，输出是这个点的环境光。


## 5. 使用pre-trained 2D diffusion models的text-to-3D论文

CVPR2024的[Text-to-3D using Gaussian Splatting]()，CVPR2024的[GaussianDreamer]()，CVPR2024的[RichDreamer](https://aigc3d.github.io/richdreamer/)，ILCR2024的[MVDream](https://github.com/bytedance/MVDream/tree/main)

### (1). MVDream: Multi-view diffusion for 3D generation

[CODE](https://github.com/bytedance/MVDream/tree/main)是有的。




## 6. 使用pre-trained 2D diffusion models的image-to-3D论文

ICCV2023的[Zero-1-to-3]()，ICLR2024Spotlight的[SyncDreamer]()，CVPR2024Highlight的[Wonder3d]()，CVPR2023的[DreamBooth3D]()，ICLR2024的[Magic123](https://guochengqian.github.io/project/magic123/)，CVPR2024的[The More You See in 2D, the More You Perceive in 3D](https://sap3d.github.io/)，ECCV2024的[3DCongealing]()，NeurIPS2023的[One-2-3-45](https://github.com/One-2-3-45/One-2-3-45/tree/master)，NeurIPS2024 Oral的[CAT3D](https://cat3d.github.io/)

### (2). Zero-1-to-3: Zero-shot One Image to 3D Object

代码[code](https://github.com/cvlab-columbia/zero123)是available的。

这篇ICCV2023年的论文的主要贡献就在于enable之前的pre-trained的diffusion model根据输入的图片和relative pose $$(R, T)$$来生成和这张图片的relative pose正好是$$(R,T)$$的新角度的图片。也就是enable diffusion模型根据camera pose生成viewpoint-conditioned的图片。

这段话是本文的核心思想：

> Since diffusion models have been trained on internet-scale data, their support of the natural image distribution likely covers most viewpoints for most objects, but these viewpoints cannot be controlled in the pre-trained models. Once we are able to teach the model a mechanism to control the camera extrinsics with which a photo is captured, then we unlock the ability to perform novel view synthesis.

### (1). 3D Congealing: 3D-Aware Image Alignment in the Wild

3DCongealing的输入是一系列category-specific的2D RGB图片，目标是将这些图片align到一起，和之前那些2D congealing的目标相同（比如[neuralcongealing]()，[GANgealing]()，[ASIC]()等）。但不同的是，3DCongealing的输入图片可以有很大的姿态差别（相机角度差别），比如说即使都是马的图片，但一张是马的侧面，一张是马的背面。那这种情况下，如果还只是做2D congealing，也就是将一张图片上的像素点和另一张图片的像素点相匹配上，就没有现实意义了（也做不了了），因为两张图片的common的semantically consistent的像素点甚至不存在了。但我们知道，它们都是描述同一类3D物体的，所以说我们可以考虑将这些2D图片，congeal或者说align到一个3D的shape上去。这就是3DCongealing这篇文章要做的。

输入仅仅是2D RGB图片，没有任何别的标注信息，这个任务是很难的。但有pre-trained的2D diffusion model，就有办法。不同于那些基于pre-trained 2D diffusion models以图片为condition来optimize一个3D representation的方法（即image-to-3D），3DCongealing对于输入的$$N$$张图片，先用[Textual Inversion](https://github.com/rinongal/textual_inversion)生成一个文本（或者文本embedding）来collaboratively描述这些图片，这个文本记为$$y^{\ast}$$。然后再利用DreamFusion里的方法，基于$$y^{\ast}$$，来optimize一个NeRF来表示3D shape。作者说那些image-to-3D的办法（比如DreamBooth3D）是利用图片来finetune预训练好的diffusion model，训练时间长，更复杂。

除了上述的optimize NeRF的loss，作者还提出了一个alignment loss。也就是对于每张输入的图片，用一个网络来预测其camera pose，再利用该camera pose和那个NeRF渲染得到这个角度的图片，再在DINO feature space上，计算这个渲染的图片和原输入图片之间的差距。

这两个loss共同作为训练网络的指标。但在implementation details里，作者说需要先将后一个loss的权重设置为0，先optimize一个NeRF出来，然后fix它了，之后再optimize camera poses。而且在optimize camera poses的时候，需要进行多次采样否则难以训练得到好的结果。这样的操作实际上是multi-stage的，减小了难度，但也降低了效果。

![20]({{ '/assets/images/diffusion_20.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}


## 7. 使用pre-trained 2D diffusion models实现3D edit/animation/deformation的论文

CVPR2024的[AlignYourGaussians]()，CVPR2024的[GaussianEditor]()，SiggraphAsia2023的[Dreameditor]()，[Animate124](https://animate124.github.io/)，NeurIPS2023的[ViCA-NeRF]()，CVPR2024年的[As-Plausible-As-Possible](https://as-plausible-as-possible.github.io/)，CVPR2024的[Dream-in-4D](https://github.com/NVlabs/dream-in-4d)，TOG2024的[TIP-Editor](https://zjy526223908.github.io/TIP-Editor/)，[GenXD](https://gen-x-d.github.io/)






























